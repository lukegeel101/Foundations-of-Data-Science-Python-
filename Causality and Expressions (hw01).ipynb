{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "80e6172c",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Homework 1: Causality and Expressions\n",
    "\n",
    "Please complete this notebook by filling in the cells provided. Before you begin, execute the following cell to load the provided tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b8e32661",
   "metadata": {},
   "outputs": [],
   "source": [
    "import otter\n",
    "grader = otter.Notebook(\"hw01.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a7bb1e",
   "metadata": {},
   "source": [
    "## Reading:\n",
    "This assignment uses material from textbook chapters [1](https://umass-data-science.github.io/190fwebsite/textbook/01/what-is-data-science/), [2](https://umass-data-science.github.io/190fwebsite/textbook/02/causality-and-experiments/), and [3](https://umass-data-science.github.io/190fwebsite/textbook/03/programming-in-python/). You should read this material before starting the assignment, and refer back to it as needed.\n",
    "\n",
    "## Answering Questions:\n",
    "For all problems that you must write explanations and sentences for, you **must** provide your answer in the designated space. Moreover, throughout this homework and all future ones, **please be sure to not re-assign variables throughout the notebook!** For example, if you use the name `max_temperature` in your answer to one question, do not assign that name a different value later on. \n",
    "\n",
    "## Deadline:\n",
    "\n",
    "This assignment is due Tuesday, September 13. Late work will not be accepted as per the [policies](https://umass-data-science.github.io/190fwebsite/policies/) page.\n",
    "\n",
    "## Collaboration:\n",
    "Directly sharing answers is not okay, but discussing problems with the course staff or with other students is encouraged. Refer to the policies page to learn more about what is an acceptable level of homework collaboration.\n",
    "\n",
    "## Getting Help:\n",
    "You should start early so that you have time to get help if you're stuck. Drop by at [office hours](https://umass-data-science.github.io/190fwebsite/office_hours/) for help and ask questions during the lab sections."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff32e69",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "## 1. Scary Arithmetic\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48191fc5",
   "metadata": {
    "manual_problem_id": "adt_1"
   },
   "source": [
    "An ad for ADT Security Systems says,\n",
    "\n",
    "> \"When you go on vacation, burglars go to work [...] According to FBI statistics, over 25% of home burglaries occur between Memorial Day and Labor Day.\"\n",
    "\n",
    "**Question 1.1: 10 points** Do the data in the ad support the claim that burglars are more likely to go to work during the time between Memorial Day and Labor Day than at other times? Please explain your answer. Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fccacb4c",
   "metadata": {},
   "source": [
    "The ad supports the claim that burglars are more likely to commit burglaries, not \"going to work\" as in go to work at their job. The ad supports the fact that burglars are more likely to this during the time between Memorial Day and Labor Day than at other times."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5db7b7",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 2. Characters in Little Women\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d93781d0",
   "metadata": {},
   "source": [
    "The textbook describes counting the number of times that the literary characters were named in each chapter of the classic book, [Little Women](https://umass-data-science.github.io/190fwebsite/textbook/01/3/little_women.txt). In computer science, the word \"character\" also refers to a letter, digit, space, or punctuation mark; any single element of a text. The following code generates a scatter plot in which each dot corresponds to a chapter of Little Women. The horizontal position of a dot measures the number of period characters \".\" in the chapter. The vertical position measures the total number of characters. Run the cell below to produce the plot, then answer the following questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0de32bfe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# This cell contains code that hasn't yet been covered in the course,\n",
    "# but you should be able to interpret the scatter plot it generates.\n",
    "\n",
    "from datascience import *\n",
    "from urllib.request import urlopen\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "little_women_url = 'https://umass-data-science.github.io/190fwebsite/textbook/01/3/little_women.txt'\n",
    "chapters = urlopen(little_women_url).read().decode().split('CHAPTER ')[1:]\n",
    "text = Table().with_column('Chapters', chapters)\n",
    "Table().with_columns(\n",
    "    'Periods',    np.char.count(chapters, '.'),\n",
    "    'Characters', text.apply(len, 0)\n",
    "    ).scatter(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b03eb92",
   "metadata": {},
   "source": [
    "**Question 2.1: 10 points** About how many periods are in the chapter with the most characters? Assign either 1, 2, 3, 4, or 5 to the name `characters_q1` below.\n",
    "\n",
    "1. 250\n",
    "2. 390\n",
    "3. 440\n",
    "4. 32,000\n",
    "5. 40,000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa869aea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q1 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "67133787",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.1</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.1 results: All test cases passed!"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ada5f4a",
   "metadata": {
    "tags": []
   },
   "source": [
    "**Question 2.2: 10 points** Which of the following chapters has the most characters per period? Assign either 1, 2, or 3 to the name `characters_q2` below.\n",
    "1. The chapter with about 60 periods\n",
    "2. The chapter with about 350 periods\n",
    "3. The chapter with about 440 periods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd315148",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "characters_q2 = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8fb3d1a0",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2.2</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q2.2 results: All test cases passed!"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca706d64",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eb9fcd0",
   "metadata": {},
   "source": [
    "To discover more interesting facts from this plot, read [Section 1.3.2](https://umass-data-science.github.io/190fwebsite/textbook/01/3/2/another-kind-of-character/) of the textbook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e82aca4",
   "metadata": {},
   "source": [
    "## 3. Names and Assignment Statements\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1738aedb",
   "metadata": {},
   "source": [
    "**Question 3.1: 10 points** When you run the following cell, Python produces a cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2510dd2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "cannot assign to literal (2912417615.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/tmp/ipykernel_26/2912417615.py\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    4 = 2 + 2\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m cannot assign to literal\n"
     ]
    }
   ],
   "source": [
    "4 = 2 + 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3df2e6",
   "metadata": {},
   "source": [
    "Choose the best explanation of what's wrong with the code, and then assign 1, 2, 3, or 4 to `names_q1` below to indicate your answer.\n",
    "\n",
    "1. Python is smart and already knows `4 = 2 + 2`.\n",
    "\n",
    "2. `4` is a number, and it doesn't make sense to make a number be a name for something else. In Python, \"`x = 2 + 2`\" means \"assign `x` as the name for the value of `2 + 2`.\"\n",
    "\n",
    "3. It should be `2 + 2 = 4`.\n",
    "\n",
    "4. I don't get an error message. This is a trick question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "620b5807",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q1 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe88a11b",
   "metadata": {},
   "source": [
    "**Question 3.2: 10 points** When you run the following cell, Python will produce another cryptic error message."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5bb8ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "two = 3\n",
    "six = two plus two\n",
    "six"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6c6dc",
   "metadata": {},
   "source": [
    "Choose the best explanation of what's wrong with the code and assign 1, 2, 3, or 4 to `names_q2` below to indicate your answer.\n",
    "\n",
    "1. The `plus` operation only applies to numbers, not the word \"two\".\n",
    "\n",
    "2. The name \"two\" cannot be assigned to the number 3.\n",
    "\n",
    "3. Two plus two is four, not six.\n",
    "\n",
    "4. The name `two` cannot be followed directly by another name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cf0cb2a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "names_q2 = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "33c815a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q3</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q3 results: All test cases passed!"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\") #I couldn't figure out why I was getting an error when trying to check q3 so I added this line to double check "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a5704e90",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong style='color: red;'><pre style='display: inline;'>q3</pre> results:</strong></p><p><strong><pre style='display: inline;'>q3 - 1</pre> result:</strong></p><pre>    Trying:\n",
       "        assert isinstance(names_q1, int)\n",
       "    Expecting nothing\n",
       "    **********************************************************************\n",
       "    Line 1, in q3 0\n",
       "    Failed example:\n",
       "        assert isinstance(names_q1, int)\n",
       "    Exception raised:\n",
       "        Traceback (most recent call last):\n",
       "          File \"/opt/conda/lib/python3.9/doctest.py\", line 1336, in __run\n",
       "            exec(compile(example.source, filename, \"single\",\n",
       "          File \"<doctest q3 0[0]>\", line 1, in <module>\n",
       "            assert isinstance(names_q1, int)\n",
       "        NameError: name 'names_q1' is not defined\n",
       "    Trying:\n",
       "        assert isinstance(names_q2, int)\n",
       "    Expecting nothing\n",
       "    ok\n",
       "</pre><p><strong><pre style='display: inline;'>q3 - 1</pre> message:</strong> If this test failed your answers are not integers</p>"
      ],
      "text/plain": [
       "q3 results:\n",
       "    q3 - 1 result:\n",
       "        Trying:\n",
       "            assert isinstance(names_q1, int)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3 0\n",
       "        Failed example:\n",
       "            assert isinstance(names_q1, int)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3 0[0]>\", line 1, in <module>\n",
       "                assert isinstance(names_q1, int)\n",
       "            NameError: name 'names_q1' is not defined\n",
       "        Trying:\n",
       "            assert isinstance(names_q2, int)\n",
       "        Expecting nothing\n",
       "        ok\n",
       "\n",
       "    q3 - 1 message: If this test failed your answers are not integers"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8a0f8c",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8aa476",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 4. Job Opportunities & Education in Rural India\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b296935",
   "metadata": {},
   "source": [
    "A [study](http://www.nber.org/papers/w16021.pdf) at UCLA investigated factors that might result in greater attention to the health and education of girls in rural India. One such factor is information about job opportunities for women. The idea is that if people know that educated women can get good jobs, they might take more care of the health and education of girls in their families, as an investment in the girls’ future potential as earners.\n",
    "\n",
    "The study focused on 160 villages outside the capital of India, all with little access to information about call centers and similar organizations that offer job opportunities to women. In 80 of the villages chosen at random, recruiters visited the village, described the opportunities, recruited women who had some English language proficiency and experience with computers, and provided ongoing support free of charge for three years. In the other 80 villages, no recruiters visited and no other intervention was made.\n",
    "\n",
    "At the end of the study period, the researchers recorded data about the school attendance and health of the children in the villages."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd3c6b96",
   "metadata": {},
   "source": [
    "**Question 4.1: 10 points** Which statement best describes the *treatment* and *control* groups for this study? Assign either 1, 2, or 3 to the name `jobs_q1` below.\n",
    "\n",
    "1. The treatment group was the 80 villages visited by recruiters, and the control group was the other 80 villages with no intervention.\n",
    "\n",
    "2. The treatment group was the 160 villages selected, and the control group was the rest of the villages outside the capital of India.\n",
    "\n",
    "3. There is no clear notion of *treatment* and *control* group in this study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "584b4bc6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs_q1 = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff7ed932",
   "metadata": {},
   "source": [
    "**Question 4.2: : 10 points** Was this an observational study or a randomized controlled experiment? Assign either 1, 2, or 3 to the name `jobs_q2` below.\n",
    "\n",
    "1. This was an observational study.\n",
    "\n",
    "2. This was a randomized controlled experiment.  \n",
    "\n",
    "3. This was a randomized observational study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6a6323d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "jobs_q2 = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89904391",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q4</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q4 results: All test cases passed!"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36810ea4",
   "metadata": {},
   "source": [
    "The treatment was performed on girls. The boys were mentioned as contrasts to argue the causal effect of the treatment on girls."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b277aef",
   "metadata": {},
   "source": [
    "Check that your answers are in the correct format. This test *does not* check that you answered correctly; only that you assigned a number successfully in each multiple-choice answer cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b663c008",
   "metadata": {
    "tags": []
   },
   "source": [
    "## 5. Differences between Universities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c62aee4",
   "metadata": {},
   "source": [
    "**Question 5.1: 5 points** Suppose you'd like to *quantify* how *dissimilar* two universities are, using three quantitative characteristics.  The US Department of Education data on [UMass](https://collegescorecard.ed.gov/school/?166629-University-of-Massachusetts-Amherst) and [UConn](https://collegescorecard.ed.gov/school/?129020-University-of-Connecticut) describes the following three variables (among many others):\n",
    "\n",
    "| Trait                                | UMass  | Uconn  |\n",
    "|--------------------------------------|--------|--------|\n",
    "| Average annual cost to attend ($)    | 18,869 | 20,023 |\n",
    "| Graduation rate (percentage)         | 77     | 82     |\n",
    "| Socioeconomic Diversity (percentage) | 24     | 21     |\n",
    "\n",
    "You decide to define the dissimilarity between two universities as the **maximum of the absolute values of the 3 differences in these values of these variables**.\n",
    "\n",
    "Using this method, compute the dissimilarity between UMass and UConn.  Name the result `dissimilarity`.  Use a single expression (a single line of code) to compute the answer.  Let Python perform all the arithmetic (like subtracting 82 from 77) rather than simplifying the expression yourself. The built-in `abs` function takes absolute values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "573f35e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1154"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dissimilarity = max(abs(20023-18869),abs(82-77),abs(24-21))\n",
    "dissimilarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "09f1aa60",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q5</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q5 results: All test cases passed!"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7949cf56",
   "metadata": {},
   "source": [
    "## 6. Nearsightedness Study\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb23a67",
   "metadata": {},
   "source": [
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "Myopia, or nearsightedness, results from a number of genetic and environmental factors. In 1999, Quinn et al studied the relation between myopia and ambient lighting at night (for example, from nightlights or room lights) during childhood."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3de95dc6",
   "metadata": {
    "manual_problem_id": "nearsightedness_1"
   },
   "source": [
    "**Question 6.1: 5 points** The data were gathered by the following procedure, reported in the study. “Between January and June 1998, parents of children aged 2-16 years [...] that were seen as outpatients in a university pediatric ophthalmology clinic completed a questionnaire on the child’s light exposure both at present and before the age of 2 years.” Was this study observational, or was it a controlled experiment? Open and edit the cell below to provide your explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00125f23",
   "metadata": {},
   "source": [
    "This study is observational because it didn't influence the response of the participants."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a838147",
   "metadata": {
    "manual_problem_id": "nearsightedness_2"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.2: 5 points** The study found that of the children who slept with a room light on before the age of 2, 55% were myopic. Of the children who slept with a night light on before the age of 2, 34% were myopic. Of the children who slept in the dark before the age of 2, 10% were myopic. The study concluded that, \"The prevalence of myopia [...] during childhood was strongly associated with ambient light exposure during sleep at night in the first two years after birth.\"\n",
    "\n",
    "Do the data support this statement? You may interpret “strongly” in any reasonable qualitative way. Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56b7365",
   "metadata": {},
   "source": [
    "Yes, the data from the study supports the argument. The children who sleep with the most light were the highest percentage of myopic and the children who slept with the least amount of light had the lowest percent of myopic. This represents a direct correlation between the amount of light a child sleeps with and how likely it is for them to become myopic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c777297a",
   "metadata": {
    "manual_problem_id": "nearsightedness_3"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.3: 5 points** On May 13, 1999, CNN reported the results of this study under the headline, “Night light may lead to nearsightedness.” Does the conclusion of the study claim that night light causes nearsightedness? Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe0c4e2",
   "metadata": {},
   "source": [
    "No the conclusion of the study doesn't claim that night light causes nearsightedness, it only stats that their is a significant correlation. Correlation does not imply causation so the cause of the nearsightedness could possibly be something other than a night light. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7193d4",
   "metadata": {
    "manual_problem_id": "nearsightedness_4"
   },
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "<!-- BEGIN QUESTION -->\n",
    "\n",
    "**Question 6.4: 5 points** The final paragraph of the CNN report said that “several eye specialists” had pointed out that the study should have accounted for heredity.\n",
    "\n",
    "Myopia is passed down from parents to children. It's reasonable to suppose that myopic parents are more likely to leave lights on in their children's rooms than other parents. In what way could this have affected the data? Open and edit the cell below to provide your answer and explanation, then run the cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb4159",
   "metadata": {},
   "source": [
    "Yes, it is reasonable to suppose that myopic parents are more likely to leave lights on in their childrens rooms than other parents. This actually wouldn't affect the quality of the data from the study, it would just mean that myopic could be less about genetics and more about the practices of your parents. If your parents are myopic but they turn your lights off at night you might be less likely to become myopic than someone whos parents aren't myopic but leave their lights on at night."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eaf1668",
   "metadata": {},
   "source": [
    "<!-- END QUESTION -->\n",
    "\n",
    "## 7. Studying the Survivors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de20cdbc",
   "metadata": {},
   "source": [
    "**Question 7.1: 5 points**The Reverend Henry Whitehead was skeptical of John Snow’s conclusion about the Broad Street pump. After the Broad Street cholera epidemic ended, Whitehead set about trying to prove Snow wrong.  (The history of the event is detailed [here](http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1034367/pdf/medhist00183-0026.pdf).)\n",
    "\n",
    "He realized that Snow had focused his analysis almost entirely on those who had died. Whitehead, therefore, investigated the drinking habits of people in the Broad Street area who had not died in the outbreak.\n",
    "\n",
    "What is the main reason it was important to study this group?\n",
    "\n",
    "1) If Whitehead had found that many people had drunk water from the Broad Street pump and not caught cholera, that would have been evidence against Snow's hypothesis.\n",
    "\n",
    "2) Survivors could provide additional information about what else could have caused the cholera, potentially unearthing another cause.\n",
    "\n",
    "3) Through considering the survivors, Whitehead could have identified a cure for cholera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "48179de9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Assign survivor_answer to 1, 2, or 3\n",
    "survivor_answer = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc9922",
   "metadata": {},
   "source": [
    "**Note:** Whitehead ended up finding further proof that the Broad Street pump played the central role in spreading the disease to the people who lived near it. Eventually, he became one of Snow’s greatest defenders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8836f75",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q7</pre></strong> passed!</p>"
      ],
      "text/plain": [
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eacf9fa",
   "metadata": {},
   "source": [
    "## 8. Submission\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6238418",
   "metadata": {},
   "source": [
    "You've finished homework 1!  Be sure to run the notebook tests and verify that they all pass, **your homework will need to pass more tests in gradescope**. Choose **Save and Checkpoint** from the **File** menu, then upload the .ipynb to gradescope to submit your work.  You may submit to gradescope as many times as you want until the deadline. Make sure to pay attention to what tests you are passing and failing after submiting!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e59a6c4",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "---\n",
    "\n",
    "To double-check your work, the cell below will rerun all of the autograder tests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "20936362",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "q2.1 results: All test cases passed!\n",
       "\n",
       "q2.2 results: All test cases passed!\n",
       "\n",
       "q3 results:\n",
       "    q3 - 1 result:\n",
       "        Trying:\n",
       "            assert isinstance(names_q1, int)\n",
       "        Expecting nothing\n",
       "        **********************************************************************\n",
       "        Line 1, in q3 0\n",
       "        Failed example:\n",
       "            assert isinstance(names_q1, int)\n",
       "        Exception raised:\n",
       "            Traceback (most recent call last):\n",
       "              File \"/opt/conda/lib/python3.9/doctest.py\", line 1336, in __run\n",
       "                exec(compile(example.source, filename, \"single\",\n",
       "              File \"<doctest q3 0[0]>\", line 1, in <module>\n",
       "                assert isinstance(names_q1, int)\n",
       "            NameError: name 'names_q1' is not defined\n",
       "        Trying:\n",
       "            assert isinstance(names_q2, int)\n",
       "        Expecting nothing\n",
       "        ok\n",
       "\n",
       "    q3 - 1 message: If this test failed your answers are not integers\n",
       "\n",
       "q4 results: All test cases passed!\n",
       "\n",
       "q5 results: All test cases passed!\n",
       "\n",
       "q7 results: All test cases passed!"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f84cd9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "otter": {
   "tests": {
    "q2.1": {
     "name": "q2.1",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(characters_q1, int)\n",
         "failure_message": "If this test failed your answer is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2.2": {
     "name": "q2.2",
     "points": 10,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(characters_q2, int)\n",
         "failure_message": "If this test failed your answer is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(names_q1, int)\n>>> assert isinstance(names_q2, int)\n",
         "failure_message": "If this test failed your answers are not integers",
         "hidden": false,
         "locked": false,
         "points": 10
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 20,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(jobs_q1, int)\n>>> assert isinstance(jobs_q2, int)\n",
         "failure_message": "If this test failed your answers are not integers",
         "hidden": false,
         "locked": false,
         "points": 10
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q5": {
     "name": "q5",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(dissimilarity, (int, float))\n",
         "failure_message": "If this test failed your answers is not a number",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q7": {
     "name": "q7",
     "points": 5,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> assert isinstance(survivor_answer, int)\n",
         "failure_message": "If this test failed your answers is not an integer",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
